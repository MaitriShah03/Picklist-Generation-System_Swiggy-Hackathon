# ğŸŸ  Swiggy Hackathon

# ğŸ“¦ Warehouse Picklist Optimization Engine

## Theme

**Operations Research | Scheduling | Algorithms | Data Science**

---

## ğŸ“Œ Overview

This project implements a **scalable, production-grade picklist generation system** for warehouse (dark store) operations.
It processes **1M+ order lines** and generates **zone-wise picklists** under real operational constraints such as:

* Picklist capacity (units & weight)
* Fragile item handling
* Order priority and cutoff deadlines
* Zone-level execution constraints

The solution is optimized for **high throughput**, **large datasets**, and **real-world feasibility**, making it suitable for **hackathons, Kaggle kernels, and warehouse planning prototypes**.

---

## ğŸ¯ Problem Objective (From Hackathon Statement)

> **Maximize effective fulfillment**
> i.e., maximize the number of SKU units picked **before loading cutoffs**, allowing **partial fulfillment**.

This system directly optimizes for:

* Early-deadline orders
* High-volume consolidation
* Zero constraint violations

---

## ğŸš€ What This System Does

Given an input CSV (`picklist_creation_data_for_hackathon_with_order_date.csv`):

1. **Automatically detects column names** (robust to schema variations)
2. **Computes absolute cutoff ordering** using:

   * POD priority
   * Order date
3. **Sorts orders using EDF (Earliest Deadline First)**
4. **Splits flows into fragile and non-fragile**
5. **Generates zone-wise picklists using a greedy heuristic**
6. **Enforces hard constraints**:

   * Max units per picklist = **2000**
   * Max weight per picklist = **200 kg**
   * Fragile picklists capped at **50 kg**
7. **Scales to 1.2M+ rows** without hanging
8. **Outputs**:

   * One CSV per picklist
   * A global `Summary.csv` for evaluation

---

## ğŸ“ Output Structure

```
.
â”œâ”€â”€ picklists/
â”‚   â”œâ”€â”€ 2025-01-15_ZONE_A_PL1.csv
â”‚   â”œâ”€â”€ 2025-01-15_ZONE_A_PL2.csv
â”‚   â”œâ”€â”€ 2025-01-15_ZONE_B_PL1.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Summary.csv
â””â”€â”€ generate_picklists.py
```

---

## ğŸ“„ Picklist CSV Columns

Each picklist file contains:

* `sku`
* `order_id`
* `store`
* `bin`
* `bin_rank`
* `qty`
* `unit_weight`
* `cutoff`
* `priority`
* `fragile`

---

## ğŸ“Š Summary.csv Columns

| Column          | Meaning                           |
| --------------- | --------------------------------- |
| picklist_file   | Generated picklist filename       |
| zone            | Warehouse zone                    |
| picklist_no     | Picklist sequence number          |
| picklist_type   | normal / fragile                  |
| total_units     | Total SKU units                   |
| total_weight    | Total weight (kg)                 |
| distinct_orders | Number of orders consolidated     |
| distinct_bins   | Number of bins visited            |
| earliest_cutoff | Earliest order cutoff in picklist |
| created_at      | Timestamp of creation             |

---

## ğŸ§  Algorithm Used

### Greedy EDF Zone-wise Bin Packing (Heuristic)

* Orders sorted by **earliest cutoff â†’ priority â†’ order_id**
* Zone-wise processing (no cross-zone mixing)
* Single-pass greedy packing
* Weight-first and unit-first constraints enforced
* Fragile items handled separately

This avoids NP-hard exact optimization while delivering **fast, near-optimal solutions**.

---

## â± Time & Space Complexity

| Component           | Complexity     |
| ------------------- | -------------- |
| Sorting             | O(N log N)     |
| Picklist generation | O(N)           |
| Output writing      | O(P)           |
| **Overall**         | **O(N log N)** |

Where:

* `N` = number of order rows
* `P` = number of picklists

Memory usage is linear in `N`.

---

## ğŸ“ˆ Evaluation Metrics (Research-Grade)

The system includes a **robust evaluation module** that computes:

### 1ï¸âƒ£ Primary Metrics

* **Total units picked before cutoff** *(proxy via EDF ordering)*
* **Picklist reduction vs baseline**

### 2ï¸âƒ£ Constraint Correctness

* Unit constraint violations
* Weight constraint violations
  â¡ï¸ **0% violations achieved**

### 3ï¸âƒ£ Utilization Metrics

* Unit utilization per picklist
* Weight utilization per picklist

### 4ï¸âƒ£ Consolidation Metrics

* Average orders per picklist
* Average bins per picklist

### 5ï¸âƒ£ Baseline Comparison

* Naive baseline: *1 order = 1 picklist*
* Reduction achieved: **~87â€“96%**

### 6ï¸âƒ£ Composite Score (PQS)

A normalized **Picklist Quality Score (0â€“1)** combining:

* Capacity utilization
* Consolidation efficiency
* Correctness
* Baseline improvement

---

## âœ… Sample Evaluation Output

```
Total Picklists Generated: 7386
Average Units per Picklist: 552
Average Weight per Picklist: 195 kg
Constraint Violations: 0
Average Weight Utilization: 97.6%
Picklist Reduction vs Baseline: 87.5%
PQS Score: 0.58
```

---

## âœ… What This Code Fully Satisfies (Problem Statement)

| Requirement                   | Status |
| ----------------------------- | ------ |
| Zone-wise picklists           | âœ… Yes  |
| Max units constraint (2000)   | âœ… Yes  |
| Max weight constraint (200kg) | âœ… Yes  |
| Fragile handling (50kg)       | âœ… Yes  |
| Order splitting allowed       | âœ… Yes  |
| Partial fulfillment           | âœ… Yes  |
| Priority-based ordering       | âœ… Yes  |
| Scales to large data          | âœ… Yes  |
| Output format (CSV)           | âœ… Yes  |

---

## âŒ What Is NOT Modeled (Explicitly)

The following **are NOT implemented yet** and are listed as future work:

| Constraint                          | Status                 |
| ----------------------------------- | ---------------------- |
| Picker shift scheduling             | âŒ Not modeled          |
| Picker assignment                   | âŒ Not modeled          |
| Picklist execution time simulation  | âŒ Not modeled          |
| Travel-time based cutoff simulation | âŒ Not modeled          |
| Late-pick wastage calculation       | âŒ Approximated via EDF |
| Multi-picker parallelism            | âŒ Not modeled          |

ğŸ‘‰ These require **time-based simulation or MILP**, beyond scope of this phase.

---

## ğŸ§ª How to Run

### Kaggle

```bash
python generate_picklists.py
```

Outputs appear in:

```
/kaggle/working/picklists
/kaggle/working/Summary.csv
```

### Testing with Fewer Rows

```python
MAX_ROWS = 200000
```

---

## ğŸ† Why This Is a Strong Hackathon Solution

âœ” Correct constraint modeling
âœ” Scales to 1M+ rows
âœ” Zero violations
âœ” Realistic warehouse logic
âœ” Clear evaluation framework
âœ” Honest about limitations
âœ” Extendable to full scheduling systems

---

## ğŸ”® Future Enhancements

* Picker shift & assignment optimization
* Time-based pick simulation
* Travel-distance minimization
* MILP comparison for small subsets
* Real-time replanning

---

## ğŸ‘¤ Author Notes

This project demonstrates:

* Algorithmic decision-making
* Operations research intuition
* Scalable system design
* Production-oriented coding
* Honest evaluation & trade-offs

---
